{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GA Data Science 10 (DAT10) - Lab4\n",
    "\n",
    "### KNN, Bokeh\n",
    "\n",
    "Justin Breucop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Last Time:\n",
    "\n",
    "- #### Numpy\n",
    "- #### Pandas\n",
    "- #### Bokeh Overview\n",
    "\n",
    "#### Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "1. Scikit Learn & Bokeh Templates: Prepping for ML\n",
    "2. KNN: Proximal Vox Populi\n",
    "\n",
    "Appendix: A note on `bokeh.charts`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Scikit Learn & Bokeh Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Where do we find Machine Learning algorithms in python?\n",
    "\n",
    "    sklearn - http://scikit-learn.org/stable/\n",
    "\n",
    "Scikit Learn is a large collection of tools for data mining & data analysis. It contains the base algorithms for many machine learning strategies and also has very developed data processing and model selection capabilities. A large amount of complex products can be built using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# from the datasets load the iris data into a variable called iris\n",
    "from sklearn import datasets\n",
    "\n",
    "sk_iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the sk_iris data set look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(sk_iris)\n",
    "# sk_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Since this is a new data type, we need to understand what methods we can use on it. \n",
    "help(sk_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Since it's like a dict object, we can explore it like we would a python dictionary (keys!!!)\n",
    "sk_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Data Visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure,output_notebook,show,VBox,HBox,gridplot \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline #display matplotlib items in the notebook (used with pd.DataFrame.plot())\n",
    "output_notebook() #display bokeh visuals within the notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sk_iris['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sk_iris['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sk_iris['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some thoughts about dataframes: They are very easy to use, work with, & plot. If you can, convert your data to one during your exploration. A fun trick to constructing dataframes when you have an array and column names is using the core constructor function `pd.DataFrame`.\n",
    "\n",
    "As a dataframe we can do some quick exploration and understand more about our data. Throughout this lab, we'll use `sk_iris` to denote the sklearn dataset and `iris` to refer to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris = pd.DataFrame(sk_iris['data'],columns=sk_iris['feature_names'])\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris.plot(kind=\"scatter\",x=1,y=2,c='r',title=\"Base Visual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But something is missing here. We have what we'd call **labelled data**. So even though our data all exists in one column, some of this data has been labelled with scientific names for irises. We can also call this the \"target\" data, or the target label we use to classify our data. To work with labels, we need to utilize the targets column of our original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sk_iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We have three possible values: 0, 1, or 2. We can construct a vector of colors to \n",
    "# make our plot easier to read.\n",
    "\n",
    "colors = []\n",
    "for target in sk_iris['target']:\n",
    "    if target == 0:\n",
    "        colors.append('red')\n",
    "    elif target == 1:\n",
    "        colors.append('orange')\n",
    "    elif target == 2:\n",
    "        colors.append('blue')\n",
    "print colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#another way to build that list, using list comprehensions:\n",
    "colorMap = {0:'red',1:'orange',2:'blue'}\n",
    "colors = [ colorMap[x] for x in sk_iris['target'] ]\n",
    "print colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We can pass our list of colors to the plot like so to get a better visual of what's going on.\n",
    "\n",
    "iris.plot(kind='scatter',x=3,y=1,c=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great start but if we want a more advanced, prettier visualization, let's use Bokeh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_x = iris.columns[1]\n",
    "feat_y = iris.columns[3]\n",
    "\n",
    "p1 = figure(plot_width=400, plot_height=400, \n",
    "            x_axis_label=feat_x, y_axis_label=feat_y)\n",
    "p1.circle(iris[feat_x], iris[feat_y], line_width=1, color=colors, alpha=0.4,size=8)\n",
    "\n",
    "show(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that with alpha setting a transparency on our data, we can see where some data overlaps and also bolder colors represent more data points at that spot.\n",
    "\n",
    "This is only 1 of many plots we can make. Let's generate the entire set programmatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plots = []\n",
    "for feat_x in iris.columns:\n",
    "    for feat_y in iris.columns:\n",
    "        \n",
    "        temp_p = figure(plot_width=200, \n",
    "                        plot_height=200, \n",
    "                        x_axis_label=feat_x, \n",
    "                        y_axis_label=feat_y\n",
    "                       )\n",
    "        temp_p.circle(iris[feat_x], \n",
    "                      iris[feat_y], \n",
    "                      line_width=1, \n",
    "                      color=colors, \n",
    "                      alpha=0.4,\n",
    "                      size=5)\n",
    "        \n",
    "        temp_p.xaxis.axis_label_text_font_size = '9pt'\n",
    "        temp_p.yaxis.axis_label_text_font_size = '9pt'\n",
    "\n",
    "        plots.append(temp_p)\n",
    "\n",
    "# gridplot takes nested lists of bokeh figures and arranges them on the grid in the positions given. \n",
    "# Passing None inserts a blank.\n",
    "\n",
    "sqrt = len(plots)**0.5\n",
    "gplots = np.array(plots).reshape(sqrt,sqrt)\n",
    "\n",
    "# To convert to a square, we reshape the array into a grid with the # of rows equal to the # of columns. \n",
    "\n",
    "#REMEMBER: gridplot takes a list of lists, so we convert gplots with the .tolists() method\n",
    "a = gridplot(gplots.tolist())\n",
    "show(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very quick way to visually inspect your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. KNN\n",
    "\n",
    "Part of the big step with this lab is understanding general sklearn syntax. Each family of algorithms have various knobs and levers to tune it appropriately but there is a general overall structure to these models that will help you as you move forward.\n",
    "1. All models need to be trained. Sklearn models have a `.fit` method for doing so.\n",
    "2. We need to use the model to make a guess. the `.predict` method takes data and returns the model's guess for the value. Stipulations around this pertain to the specific model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's re-assign the data to standard named variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = sk_iris.data\n",
    "y = sk_iris.target\n",
    "Names = sk_iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Split the data into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# is there a function to do that in sklearn?\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train KNN classifier defined function on the train data\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myknn = KNeighborsClassifier(3).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's figure out how good our model is. The traditional score is what percentage of my labels did I correctly identify. This is called **Precision**. There are other types of statistical scores but we will start here. We'll ask our model to predict what the labels for our test set are, then generate a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myknn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "\n",
    "# We'll build this together.\n",
    "\n",
    "print \"Number correct:\",correct\n",
    "print \"Score:\",float(correct)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was easy enough. Sklearn also has an easy method for generating a score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myknn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn also has a way of showing more information about the prediction. Here, we're using sklearn.metrics.classification_report to generate a more informative picture. The wikipedia pages for recall, f1-score, and support are also informative if you're looking to understand more.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print metrics.classification_report([sk_iris['target_names'][label] for label in y_test], \n",
    "                                    [sk_iris['target_names'][label] for label in myknn.predict(X_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #1\n",
    "### How does the model perform when you increase the number of neighbors?  \n",
    "\n",
    "### Can you plot the score as a function of the number of neighbors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###How much do the scores vary each time you shuffle and split?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Appendix: Bokeh.charts & Bar Chart Example\n",
    "\n",
    "Some of you have noticed the `bokeh.charts` area so I'll discuss that here a bit. Bokeh.charts is high level, meaning it abstracts a lot of details and generates plots easier than using `bokeh.plotting`. If you're still with me, this translates to less control but faster visuals. Stick with `bokeh.plotting` for now but if you find that you really need bar charts, this is an example of how to generate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flowers = []\n",
    "for val in sk_iris['target']:\n",
    "    flowers.append(sk_iris['target_names'][val])\n",
    "\n",
    "iris['target'] = flowers\n",
    "iris_agg = iris.groupby('target').mean()\n",
    "iris_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "for target in iris_agg.index:\n",
    "    data[target] = iris_agg.loc[target].values\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.charts import Bar, show\n",
    "\n",
    "p=Bar(data, cat=list(iris_agg.columns), title=\"Bar example\",\n",
    "        xlabel='Flowers', ylabel='Average Length (cm)', width=600, height=600, legend=\"top_right\")\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
